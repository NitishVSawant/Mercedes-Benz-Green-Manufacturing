{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.layers import Dense,Input,Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Label Encoding and Normalising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1. Import dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 378)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2. Removing outliers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers\n",
    "data = data[data['y']<=150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4194, 378)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3. Split the dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['y'])\n",
    "Y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3355, 377)\n",
      "(839, 377)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.4. Label encoding of categorical features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(dataset):\n",
    "    \"\"\"\n",
    "    Returns dictionary of Label encoding of categorical features\n",
    "    \"\"\"\n",
    "    a = dataset.value_counts()\n",
    "    \n",
    "    #Get categories which occur more than 5 times in dataset\n",
    "    b = list(filter(lambda x:x>5,a.values))    \n",
    "    c = list(a.index[0:len(b)])\n",
    "\n",
    "    return {j:i+1 for i,j in enumerate(c)}  #Dictionary of labels, unknown categories are assigned label 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_labels = label_encoding(X_train['X0'])\n",
    "x1_labels = label_encoding(X_train['X1'])\n",
    "x2_labels = label_encoding(X_train['X2'])\n",
    "x3_labels = label_encoding(X_train['X3'])\n",
    "x5_labels = label_encoding(X_train['X5'])\n",
    "x6_labels = label_encoding(X_train['X6'])\n",
    "x8_labels = label_encoding(X_train['X8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_mapping = [x0_labels,x1_labels,x2_labels,x3_labels,x5_labels,x6_labels,x8_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('categ_mapping.pkl', 'wb') as f:\n",
    "    pickle.dump(categ_mapping, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['X0'] = [x0_labels[i] if x0_labels.get(i) is not None else 0 for i in X_train['X0']]\n",
    "X_train['X1'] = [x1_labels[i] if x1_labels.get(i) is not None else 0 for i in X_train['X1']]\n",
    "X_train['X2'] = [x2_labels[i] if x2_labels.get(i) is not None else 0 for i in X_train['X2']]\n",
    "X_train['X3'] = [x3_labels[i] if x3_labels.get(i) is not None else 0 for i in X_train['X3']]\n",
    "X_train['X5'] = [x5_labels[i] if x5_labels.get(i) is not None else 0 for i in X_train['X5']]\n",
    "X_train['X6'] = [x6_labels[i] if x6_labels.get(i) is not None else 0 for i in X_train['X6']]\n",
    "X_train['X8'] = [x8_labels[i] if x8_labels.get(i) is not None else 0 for i in X_train['X8']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.5. Normalise categorical features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features from feature engineering which are non-binary\n",
    "scale_features = ['ID','X0','X1','X2','X3','X5','X6','X8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[scale_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_features_min = {i:j for i,j in zip(scale_features,scaler.data_min_)}\n",
    "scale_features_max = {i:j for i,j in zip(scale_features,scaler.data_max_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_features = [scale_features,scale_features_min,scale_features_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('norm_features.pkl', 'wb') as f:\n",
    "    pickle.dump(norm_features, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.1. Final Function 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(dataset):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function returns the predictions for input dataset\n",
    "    \n",
    "    Following files are needed in directory to run this function:\n",
    "        1. categ_mapping.pkl - Contains the label encoding mapping of categorical features\n",
    "        2. feature_engg.npy - Names of feature engineering variables\n",
    "        3. num_features.npy - Names of binary features in the dataset\n",
    "        4. norm_features.pkl - Contains utilies for normalising the non-binary features\n",
    "        5. top_features.npy - Contains names of top features obtained during feature selection\n",
    "        6. ensemble_drop_base_models.npy - Contains model names to drop from ensemble base models\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    #Functions\n",
    "    def feature_engineering(data,feature_engg):\n",
    "        \"\"\"\n",
    "        Adding new features to dataset\n",
    "        \"\"\"\n",
    "        for i in tqdm(feature_engg):\n",
    "            if len(i.split('_'))==2:\n",
    "                a,b = i.split('_')\n",
    "                data[i] = data[a] + data[b]\n",
    "            else:\n",
    "                a,b,c = i.split('_')\n",
    "                data[i] = data[a] + data[b] + data[c]\n",
    "        return data\n",
    "    \n",
    "    def normalizer(obs,min_value,max_value):\n",
    "        \"\"\"\n",
    "        This function normalises the input value.\n",
    "        \"\"\"\n",
    "        return (obs - min_value)/(max_value-min_value)\n",
    "    \n",
    "    print('\\n1. Data preparation')\n",
    "    print('\\n1.1. Label encoding of categorical features')\n",
    "    #Load categorical label encoding mapping\n",
    "    with open('categ_mapping.pkl', 'rb') as f:\n",
    "        categ_mapping = pickle.load(f)\n",
    "    \n",
    "    #Encode Categorical variables\n",
    "    x0_labels,x1_labels,x2_labels,x3_labels,x5_labels,x6_labels,x8_labels = categ_mapping\n",
    "    dataset['X0'] = [x0_labels[i] if x0_labels.get(i) is not None else 0 for i in dataset['X0']]\n",
    "    dataset['X1'] = [x1_labels[i] if x1_labels.get(i) is not None else 0 for i in dataset['X1']]\n",
    "    dataset['X2'] = [x2_labels[i] if x2_labels.get(i) is not None else 0 for i in dataset['X2']]\n",
    "    dataset['X3'] = [x3_labels[i] if x3_labels.get(i) is not None else 0 for i in dataset['X3']]\n",
    "    dataset['X5'] = [x5_labels[i] if x5_labels.get(i) is not None else 0 for i in dataset['X5']]\n",
    "    dataset['X6'] = [x6_labels[i] if x6_labels.get(i) is not None else 0 for i in dataset['X6']]\n",
    "    dataset['X8'] = [x8_labels[i] if x8_labels.get(i) is not None else 0 for i in dataset['X8']]\n",
    "    \n",
    "    #Load feature names for feature engineering\n",
    "    print('\\n1.2. Feature engineering')\n",
    "    feature_engg = np.load('feature_engg.npy',allow_pickle=True)\n",
    "    \n",
    "    #Feature engineering\n",
    "    dataset = feature_engineering(dataset,feature_engg)\n",
    "    \n",
    "    #Load names of binary features\n",
    "    num_features = np.load('num_features.npy',allow_pickle=True)\n",
    "    \n",
    "    #Combine features\n",
    "    final_features = ['ID','X0','X1','X2','X3','X5','X6','X8'] + list(num_features) + list(feature_engg)\n",
    "    dataset = dataset[final_features]\n",
    "    \n",
    "    print('\\n1.3. Normalising of non-binary features')\n",
    "    \n",
    "    #Load utilies for normalising features\n",
    "    with open('norm_features.pkl', 'rb') as g:\n",
    "        norm_features = pickle.load(g)\n",
    "    \n",
    "    #Normalise features\n",
    "    scale_features, scale_features_min, scale_features_max = norm_features\n",
    "    for i in tqdm(scale_features):\n",
    "        dataset.loc[:,i] = dataset.loc[:,i].apply(normalizer,min_value=scale_features_min[i],max_value=scale_features_max[i])\n",
    "    \n",
    "    #Load names of top features\n",
    "    top_features = np.load('top_features.npy')\n",
    "    \n",
    "    print('\\n2. Model Prediction using Ensemble Bagging')\n",
    "    \n",
    "    features = top_features[:15]\n",
    "    X_pred = dataset[features]\n",
    "    X_pred.columns = ['f'+str(i) for i in range(len(X_pred.columns))]\n",
    "\n",
    "    drop_models = np.load('ensemble_drop_base_models.npy')\n",
    "    \n",
    "    n_folds = 10\n",
    "    n_splits = 50\n",
    "    pred = np.zeros((X_pred.shape[0],n_splits-len(drop_models)))\n",
    "\n",
    "    ml_models = [i+1 for i in range(n_splits) if i+1 not in drop_models]\n",
    "\n",
    "    for i,ml in enumerate(tqdm(ml_models)):\n",
    "        a = np.zeros((pred.shape[0],n_folds))\n",
    "        for j in range(n_folds):\n",
    "            m = joblib.load('ml_models/ml_model_'+str(ml)+'_fold_'+str(j+1)+'.pkl')\n",
    "            a[:,j] = m.predict(X_pred)\n",
    "        pred[:,i] = np.mean(a,axis=1)\n",
    "\n",
    "    test_pred = pred\n",
    "    \n",
    "    #Take average of all predictions\n",
    "    final_pred = np.mean(test_pred,axis=1)\n",
    "    \n",
    "    print('Time taken for predictions: {} seconds'.format(round(time.time()-start)))\n",
    "    \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Data preparation\n",
      "\n",
      "1.1. Label encoding of categorical features\n",
      "\n",
      "1.2. Feature engineering\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0cc771ad1c4e81ae95ca4441cb259b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=314.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1.3. Normalising of non-binary features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840b85e0639d4ae8b2627d75523c08d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. Model Prediction using Ensemble Bagging\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e16c3d2b894c43b52e42edf61b9f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken for predictions: 37 seconds\n"
     ]
    }
   ],
   "source": [
    "test_pred = final_fun_1(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame()\n",
    "pred['ID'] = test.ID\n",
    "pred['y'] = test_pred\n",
    "pred.to_csv('final_test_pred2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.2. Final Function 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2(X,Y):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function returns the R-squared value. \n",
    "    \n",
    "    Following files are needed in directory to run this function:\n",
    "        1. categ_mapping.pkl - Contains the label encoding mapping of categorical features\n",
    "        2. feature_engg.npy - Names of feature engineering variables\n",
    "        3. num_features.npy - Names of binary features in the dataset\n",
    "        4. norm_features.pkl - Contains utilies for normalising the non-binary features\n",
    "        5. top_features.npy - Contains names of top features obtained during feature selection\n",
    "    \"\"\"\n",
    "    \n",
    "    final_pred = final_fun_1(X)\n",
    "    r_squared_value = r2_score(Y,final_pred) \n",
    "    \n",
    "    return r_squared_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train.sample(2000)\n",
    "X = data.drop(columns=['y'])\n",
    "Y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Data preparation\n",
      "\n",
      "1.1. Label encoding of categorical features\n",
      "\n",
      "1.2. Feature engineering\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbd3dc29e7646549afbf47ecc753ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=314.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1.3. Normalising of non-binary features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17575c1097741e6833d8ecac1e2d5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. Model Prediction using Ensemble Bagging\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6ea938016e4fa3a0f54678b99e172a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken for predictions: 29 seconds\n"
     ]
    }
   ],
   "source": [
    "score = final_fun_2(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value: 0.5999049866739438\n"
     ]
    }
   ],
   "source": [
    "print('R-squared value:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
